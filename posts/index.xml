<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on xhikun</title>
    <link>https://blog.wjxuikun.eu.org/posts/</link>
    <description>Recent content in Posts on xhikun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 04 Aug 2023 16:58:01 +0800</lastBuildDate><atom:link href="https://blog.wjxuikun.eu.org/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>U-2-Net 进行积水区域分割</title>
      <link>https://blog.wjxuikun.eu.org/posts/ai/u_2_net_train/</link>
      <pubDate>Fri, 04 Aug 2023 16:58:01 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/ai/u_2_net_train/</guid>
      <description>项目需求，需要分割出图片中积水区域，以及简单计算其面积，本次使用U-2-Net训练，并记录结果 U-2-Net官方github上面的pytorch是0.4.0版本，自己本地是1.8.0，起初以为出问题，不过最终训练过程却出奇的顺利
Git 官网
数据集准备 训练代码默认使用DUTS数据集，下载后的标签如图 显著目标检测任务是将图像中的显著区域（前景）与非显著区域（背景）分割开来，结果用黑白图来表示，即前景用像素值255表示，背景用0来表示，一般的到的黑白图是1维的，所以如果要通过端到端来实现，那么模型的最后一个卷积层输出的通道数应该为1。这有点类似于语义分割的二分类任务，但是与语义分割不同的是，显著目标检测没有既定类别的分类对象，而语义分割则是有固定类别的分类任务，显著目标检测无法固定分类数，从结果图上看，显著目标检测（结果图为灰度图）更像是回归任务。
=====
接下来准备自己的标签，我的需求是分割出图片中有水的区域，最开始是使用所有包含积水的图片训练，但这样训练模型会将没有积水的区域也识别有积水，因此我增加了同一场景无积水的图作为负样本 修改代码 第一个错 负样本的标签即全图为背景，值都为0，因此默认的data_loader.py 会报错
ValueError: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array with array.copy().) 这个错误发生在你试图将一个有负步长的NumPy数组转换为PyTorch张量时。步长是在内存中跳过的字节数，以便在所有轴都为单位时，跳转到下一个元素。
在NumPy中，当数组是另一个被-1步长切片的数组的视图时，该数组可能有负步长。目前，PyTorch不支持负步长，因此会出现这个错误。
要解决这个问题，你可以在将NumPy数组转换为PyTorch张量之前复制一份你的NumPy数组。当你在一个NumPy数组上调用 .copy() 方法时，它会创建一个具有正步长的新数组。
在date_loader.py文件 ToTensorLab类中 修改即可
第二错 File &amp;#34;/home/user/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py&amp;#34;, line 55, in default_collate return torch.stack(batch, 0, out=out) RuntimeError: result type Double can&amp;#39;t be cast to the desired output type Byte 这个错误出现在 torch.</description>
    </item>
    
    <item>
      <title>笔记本连接wifi，设备直连笔记本，共享手机热点</title>
      <link>https://blog.wjxuikun.eu.org/posts/question/share_net/</link>
      <pubDate>Thu, 27 Jul 2023 15:52:01 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/question/share_net/</guid>
      <description>记录一下，今天的操作，由于设备在户外，没有外网，但是需要设备需要连接外网安装依赖包，因此通过笔记本连接手机热点，将网络共享跟设备 （补充：另外，如果是服务器的话，可以直接usb连接手机和服务器，手机设置一下USB共享网络，服务器设置为DHCP,即可将网络共享给服务器）
首先，将设备与笔记本直连，将直连的网口ip设置为设备的ip在同一个网段，且能ping通，我这里设备有两个网口， 一个默认ip为192.168.1.30，另一个为192.168.2.30，我这里连接1网口，因此ping 192.168.1.30 选择wifi,将笔记本wifi设置共享，选择设备与笔记本直连网口 确认之后，直连网口ip会改变，将直连网口ip设置为和设备同一网段 此时本地电脑能 ping 通设备ip即可，我这里为ping 192.168.1.30 重点：假设网口ip为192.168.1.45，通过ssh登录设备，在设备上添加默认网关：route add default gw 192.168.1.45 添加之后即有外网了 </description>
    </item>
    
    <item>
      <title>ubuntu安装docker,并且支持GPU</title>
      <link>https://blog.wjxuikun.eu.org/posts/docker/install_docker_gpu/</link>
      <pubDate>Thu, 20 Jul 2023 11:01:42 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/docker/install_docker_gpu/</guid>
      <description>使用官方安装脚本自动安装docker curl -fsSL https://test.docker.com -o test-docker.sh sudo sh test-docker.sh 安装完后，终端输入docker 即可验证
安装NVIDIA Container Runtime以支持docker调用GPU 添加脚本install_docker_gpu.sh
sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \ sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID) sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \ sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list sudo apt-get update 执行脚本
sh install_docker_gpu.sh 安装
apt-get install nvidia-container-runtime 验证
docker run -it --rm --gpus all ubuntu nvidia-smi 到这里，支持调用GPU的docker就安装完成了，加入&amp;quot;&amp;ndash;gpus&amp;quot;参数，即可在docker容器内使用GPU资源</description>
    </item>
    
    <item>
      <title>自启动</title>
      <link>https://blog.wjxuikun.eu.org/posts/question/self-starting/</link>
      <pubDate>Sun, 02 Jul 2023 15:46:50 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/question/self-starting/</guid>
      <description>ubuntu-18.04不能像ubuntu14一样通过编辑rc.local来设置开机启动脚本，通过下列简单设置后，可以使rc.local重新发挥作用。
建立rc-local.service文件 sudo vi /etc/systemd/system/rc-local.service 将下列内容复制进rc-local.service文件 [Unit] Description=/etc/rc.local Compatibility ConditionPathExists=/etc/rc.local [Service] Type=forking ExecStart=/etc/rc.local start TimeoutSec=0 StandardOutput=tty RemainAfterExit=yes SysVStartPriority=99 [Install] WantedBy=multi-user.target 创建文件rc.local　sudo vi /etc/rc.local 将下列内容复制进rc.local文件 #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will &amp;#34;exit 0&amp;#34; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits.</description>
    </item>
    
    <item>
      <title>python、ubuntu换源</title>
      <link>https://blog.wjxuikun.eu.org/posts/question/yuan/</link>
      <pubDate>Sat, 01 Jul 2023 11:35:59 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/question/yuan/</guid>
      <description>简单记录一下曾经用过的下载源，包含python,ubuntu
python # 腾讯 http://mirrors.tencentyun.com/pypi/simple # 阿里 https://mirrors.aliyun.com/pypi/simple # 豆瓣 https://pypi.douban.com/simple # 中科大 https://pypi.mirrors.ustc.edu.cn/simple/ # 清华 https://pypi.tuna.tsinghua.edu.cn/simple ubuntu 推荐一个ubuntu16.04的arm源，之前部署某厂商的边缘盒子用到，但是版本号又是18.04的，很奇怪，不对最终也能用，因此记录一下
# 阿里云 deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe deb-src http://mirrors.</description>
    </item>
    
    <item>
      <title>利用python opencv，将处理过后的图片，保存为html5支持的mp4</title>
      <link>https://blog.wjxuikun.eu.org/posts/question/opencv_tohtml5/</link>
      <pubDate>Fri, 30 Jun 2023 16:22:11 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/question/opencv_tohtml5/</guid>
      <description>我使用的是ubuntu系统，遇到python opencv生成的视频，无法在浏览器上播放，之前用C++ 写的时候，直接将fourcc设置为h264编码的一种即可（apt 直接装的opencv）
CV_FOURCC(&amp;#39;a&amp;#39;, &amp;#39;v&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;1&amp;#39;) 以为python opencv也可简单的设置，但是不行，google一下，发现python opencv 通过pip下载的不包含h264编码器，需要从源码编译才行，个人觉得太麻烦，直接舍弃，于是采用ffmepg转码，简单粗暴。
#主要转码代码为 def convertToMP4(inputPath): outputPath = inputPath[:-3] + &amp;#39;mp4&amp;#39; cmd = &amp;#39;ffmpeg -y -i {} -vcodec h264 {}&amp;#39;.format(input_file_path, output_file_path) subprocess.call(cmd, shell=True) return outputPath 转换完成的视频，可流畅的在浏览器上播放</description>
    </item>
    
    <item>
      <title>第一篇博客</title>
      <link>https://blog.wjxuikun.eu.org/posts/daily/first/</link>
      <pubDate>Wed, 28 Jun 2023 17:03:21 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/daily/first/</guid>
      <description>我的第一篇博客 今天，我终于开通了自己的博客网站！我感到非常激动和兴奋，这是一个全新的开始。
写博客对我来说意义重大。它是我分享知识、记录经验和思考的平台。我希望通过博客与读者们分享我的见解、学习心得和成长故事。
我的博客主题是基于 Hugo 构建的，它提供了强大的功能和灵活的扩展性。我选择了一个简洁而美观的主题，以确保内容能够更好地呈现。
我玩博客主要目的，主要记录一些冲浪时遇到好玩的东西，免得自己忘记。</description>
    </item>
    
    <item>
      <title>ubuntu 18.04 mmdetection 训练mask_rcnn</title>
      <link>https://blog.wjxuikun.eu.org/posts/ai/mmdet_mask/</link>
      <pubDate>Tue, 30 Jun 2020 16:22:11 +0800</pubDate>
      
      <guid>https://blog.wjxuikun.eu.org/posts/ai/mmdet_mask/</guid>
      <description>Git 官网 安装教程以及数据集准备，可以根据自己想要跑的网络准备。下面记录一下这次跑mask_rcnn的过程。
数据集准备 这次在数据上面花了很多时间，一开始自己使用精灵标注助手标注，但是感觉后续处理很麻烦。后来借鉴了一下别人做数据集的方式，采用labelme进行标注，再通过mask出的区域，反算出物体的位置标签。
我在训练mask_rcnn的时候，采用的是coco数据集的格式，首先，先按照coco数据集的格式，创建文件夹。建议将data放在mmdetection。 之后，需要调用一个labelme2coco.py脚本，生成instance.json文件（coco数据集格式），另外这个脚本需要把labelme生成的json和图片放在一起，当然也可以不放在一起，可以自己根据情况修改。 # -*- coding:utf-8 -*- import argparse import json import matplotlib.pyplot as plt import skimage.io as io import cv2 from labelme import utils import numpy as np import glob import PIL.Image from shapely.geometry import Polygon class labelme2coco(object): def __init__(self, labelme_json=[], save_json_path=&amp;#39;./new.json&amp;#39;): &amp;#39;&amp;#39;&amp;#39; :param labelme_json: 所有labelme的json文件路径组成的列表 :param save_json_path: json保存位置 &amp;#39;&amp;#39;&amp;#39; self.labelme_json = labelme_json self.save_json_path = save_json_path self.images = [] self.categories = [] self.annotations = [] # self.</description>
    </item>
    
  </channel>
</rss>
